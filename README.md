# Distillation-of-Faster-rcnn
Distillation for faster rcnn in classification,regression,feature level,feature level +mask
The code is heavily borrowed from :
1.
http://papers.nips.cc/paper/6676-learning-efficient-object-detection-models-with-knowledge-distillation.pdf
2.
cvf.com/content_CVPR_2019/html/Wang_Distilling_Object_Detectors_With_Fine-Grained_Feature_Imitation_CVPR_2019_paper.html
code:
 https://github.com/twangnh/Distilling-Object-Detectors
 
